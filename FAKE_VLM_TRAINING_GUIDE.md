# Qwen2.5-VL-3B è®­ç»ƒæŒ‡å— - ä½¿ç”¨å‡æ•°æ®é›†

æœ¬æŒ‡å—å°†æ‰‹æŠŠæ‰‹æ•™ä½ å¦‚ä½•ä½¿ç”¨ verl æ¡†æ¶è®­ç»ƒ Qwen2.5-VL-3B-Instruct æ¨¡å‹ï¼ŒåŸºäºä½ çš„è™šå‡æ•°æ®é›†ã€‚

## ğŸ“‹ å‰ç½®æ¡ä»¶

- **æ¨¡å‹è·¯å¾„**: `/home/vgc7798/canyu_models/models--Qwen--Qwen2.5-VL-3B-Instruct`
- **æ•°æ®é›†è·¯å¾„**: `/home/vgc7798/projects_p32509/userdata/zheyu/world_model_vlm/benchmark/prompt/fake_dataset.json`
- **verl ä»“åº“**: `/gpfs/projects/p32509/userdata/zheyu/verl_Uky`

## ğŸš€ å¿«é€Ÿå¼€å§‹ (3 æ­¥å®Œæˆ)

### ç¬¬ 1 æ­¥: é¢„å¤„ç†æ•°æ®

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å°†ä½ çš„ JSON æ•°æ®è½¬æ¢ä¸º verl æ”¯æŒçš„ parquet æ ¼å¼ã€‚

```bash
cd /gpfs/projects/p32509/userdata/zheyu/verl_Uky

# è¿è¡Œæ•°æ®é¢„å¤„ç†è„šæœ¬
python examples/data_preprocess/fake_dataset_vlm.py \
    --input_json /home/vgc7798/projects_p32509/userdata/zheyu/world_model_vlm/benchmark/prompt/fake_dataset.json \
    --local_save_dir ~/data/fake_vlm_dataset \
    --train_ratio 0.9
```

**è¿™ä¸€æ­¥åšäº†ä»€ä¹ˆ?**
- è¯»å–ä½ çš„ JSON æ•°æ®é›†
- æå–å›¾åƒè·¯å¾„å’Œé—®é¢˜
- æ ¼å¼åŒ–ä¸ºå¤šé€‰é¢˜ (MCQ) æ ¼å¼
- åˆ†å‰²ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›† (90%/10%)
- ä¿å­˜ä¸º parquet æ–‡ä»¶

**è¾“å‡ºä½ç½®**: `~/data/fake_vlm_dataset/`
- `train.parquet` - è®­ç»ƒæ•°æ®
- `test.parquet` - æµ‹è¯•æ•°æ®

### ç¬¬ 2 æ­¥: éªŒè¯æ•°æ®

æ£€æŸ¥æ•°æ®æ˜¯å¦æ­£ç¡®ç”Ÿæˆ:

```bash
python -c "
import pandas as pd
df = pd.read_parquet('~/data/fake_vlm_dataset/train.parquet')
print(f'è®­ç»ƒæ ·æœ¬æ•°: {len(df)}')
print(f'åˆ—å: {df.columns.tolist()}')
print(f'ç¬¬ä¸€ä¸ªæ ·æœ¬:')
print(df.iloc[0])
"
```

### ç¬¬ 3 æ­¥: å¼€å§‹è®­ç»ƒ

ç°åœ¨å¯ä»¥å¯åŠ¨è®­ç»ƒäº†ï¼

```bash
cd /gpfs/projects/p32509/userdata/zheyu/verl_Uky

# ä½¿ç”¨ vLLM å¼•æ“è®­ç»ƒ
bash examples/grpo_trainer/run_qwen2_5_vl-3b_fake_dataset.sh vllm

# æˆ–è€…ä½¿ç”¨ SGLang å¼•æ“ (æ›´å¿«)
bash examples/grpo_trainer/run_qwen2_5_vl-3b_fake_dataset.sh sglang
```

## ğŸ“ åˆ›å»ºçš„æ–‡ä»¶è¯´æ˜

### 1. æ•°æ®é¢„å¤„ç†è„šæœ¬
**ä½ç½®**: `examples/data_preprocess/fake_dataset_vlm.py`

**åŠŸèƒ½**:
- è§£æä½ çš„ JSON æ ¼å¼æ•°æ®
- æå–å›¾åƒè·¯å¾„ (ä» `<image>path</image>` æ ‡ç­¾)
- å¤„ç†å¤šé€‰é¢˜æ ¼å¼
- ç”Ÿæˆè®­ç»ƒå’Œæµ‹è¯•é›†

**å…³é”®å‚æ•°**:
- `--input_json`: è¾“å…¥ JSON æ–‡ä»¶è·¯å¾„
- `--local_save_dir`: è¾“å‡ºç›®å½•
- `--train_ratio`: è®­ç»ƒé›†æ¯”ä¾‹ (é»˜è®¤ 0.9)

### 2. Reward Function (å¥–åŠ±å‡½æ•°)
**ä½ç½®**: `verl/utils/reward_score/mcq_vlm.py`

**åŠŸèƒ½**:
- ä»æ¨¡å‹è¾“å‡ºä¸­æå–ç­”æ¡ˆ (A/B/C/D)
- ä¸æ­£ç¡®ç­”æ¡ˆæ¯”è¾ƒ
- è¿”å›å¥–åŠ±åˆ†æ•° (1.0 = æ­£ç¡®, 0.0 = é”™è¯¯)

**æ”¯æŒçš„ç­”æ¡ˆæ ¼å¼**:
- "The answer is A"
- "Answer: B"
- "é€‰æ‹© C"
- å•ç‹¬çš„å­—æ¯ "A"

### 3. è®­ç»ƒè„šæœ¬
**ä½ç½®**: `examples/grpo_trainer/run_qwen2_5_vl-3b_fake_dataset.sh`

**å…³é”®é…ç½®**:
```bash
# æ¨¡å‹é…ç½®
MODEL_PATH: Qwen2.5-VL-3B-Instruct è·¯å¾„
ENGINE: vllm æˆ– sglang

# è®­ç»ƒè¶…å‚æ•°
learning_rate: 1e-6
batch_size: 256
epochs: 20
n_samples_per_prompt: 5  (æ¯ä¸ª prompt ç”Ÿæˆ 5 ä¸ªå›ç­”)

# GPU é…ç½®
n_gpus_per_node: 8
nnodes: 1
```

## ğŸ”§ è‡ªå®šä¹‰é…ç½®

### è°ƒæ•´æ‰¹æ¬¡å¤§å° (å¦‚æœæ˜¾å­˜ä¸è¶³)

ç¼–è¾‘ `run_qwen2_5_vl-3b_fake_dataset.sh`:

```bash
# å‡å°æ‰¹æ¬¡å¤§å°
data.train_batch_size=128  # ä» 256 æ”¹ä¸º 128
actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=4  # ä» 8 æ”¹ä¸º 4
```

### ä¿®æ”¹å­¦ä¹ ç‡

```bash
actor_rollout_ref.actor.optim.lr=5e-7  # ä» 1e-6 æ”¹ä¸º 5e-7
```

### æ›´æ”¹è®­ç»ƒè½®æ•°

```bash
trainer.total_epochs=30  # ä» 20 æ”¹ä¸º 30
```

### ä½¿ç”¨æ›´å°‘ GPU

```bash
trainer.n_gpus_per_node=4  # ä» 8 æ”¹ä¸º 4
```

## ğŸ“Š ç›‘æ§è®­ç»ƒ

è®­ç»ƒè¿‡ç¨‹ä¼šè‡ªåŠ¨è®°å½•åˆ° WandB:

```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
wandb login  # é¦–æ¬¡éœ€è¦ç™»å½•

# é¡¹ç›®åç§°: verl_grpo_fake_vlm
# å®éªŒåç§°: qwen2_5_vl_3b_spatial_reasoning
```

æˆ–è€…æŸ¥çœ‹æœ¬åœ°æ—¥å¿—:

```bash
# è®­ç»ƒè¾“å‡ºåœ¨ç»ˆç«¯å®æ—¶æ˜¾ç¤º
# æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜åœ¨: ~/verl_experiments/
```

## ğŸ› å¸¸è§é—®é¢˜

### é—®é¢˜ 1: æ‰¾ä¸åˆ°å›¾åƒæ–‡ä»¶

**é”™è¯¯**: `Warning: Image not found: /path/to/image.jpeg`

**è§£å†³**:
ç¡®ä¿ JSON ä¸­çš„å›¾åƒè·¯å¾„æ˜¯ç»å¯¹è·¯å¾„ä¸”æ–‡ä»¶å­˜åœ¨:
```bash
# æ£€æŸ¥å›¾åƒæ˜¯å¦å­˜åœ¨
ls /home/vgc7798/zheyu_b1222/example.jpeg
```

### é—®é¢˜ 2: æ˜¾å­˜ä¸è¶³ (OOM)

**è§£å†³æ–¹æ¡ˆ 1**: å‡å°æ‰¹æ¬¡å¤§å°
```bash
data.train_batch_size=128  # å‡åŠ
actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=4
```

**è§£å†³æ–¹æ¡ˆ 2**: å¯ç”¨æ˜¾å­˜ä¼˜åŒ–
```bash
actor_rollout_ref.actor.fsdp_config.param_offload=True
actor_rollout_ref.actor.fsdp_config.optimizer_offload=True
```

**è§£å†³æ–¹æ¡ˆ 3**: å‡å°‘é‡‡æ ·æ•°
```bash
actor_rollout_ref.rollout.n=3  # ä» 5 æ”¹ä¸º 3
```

### é—®é¢˜ 3: æ•°æ®æ ¼å¼é”™è¯¯

**æ£€æŸ¥æ•°æ®æ ¼å¼**:
```python
import pandas as pd
df = pd.read_parquet('~/data/fake_vlm_dataset/train.parquet')

# æ£€æŸ¥å¿…éœ€çš„åˆ—
required_cols = ['prompt', 'images', 'reward_model', 'ability']
for col in required_cols:
    assert col in df.columns, f"ç¼ºå°‘åˆ—: {col}"

print("æ•°æ®æ ¼å¼æ­£ç¡®!")
```

### é—®é¢˜ 4: æ¨¡å‹è·¯å¾„é”™è¯¯

**æ£€æŸ¥æ¨¡å‹è·¯å¾„**:
```bash
# æ‰¾åˆ°æ­£ç¡®çš„ snapshot ç›®å½•
ls -la /home/vgc7798/canyu_models/models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/

# è„šæœ¬ä¼šè‡ªåŠ¨é€‰æ‹©æœ€æ–°çš„ snapshot
```

## ğŸ¯ éªŒè¯è®­ç»ƒç»“æœ

è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹ä¼šä¿å­˜åœ¨:
```bash
~/verl_experiments/qwen2_5_vl_3b_spatial_reasoning/
```

### æµ‹è¯•è®­ç»ƒåçš„æ¨¡å‹

```python
from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor
from PIL import Image

# åŠ è½½è®­ç»ƒåçš„æ¨¡å‹
model_path = "~/verl_experiments/qwen2_5_vl_3b_spatial_reasoning/checkpoint-final"
model = Qwen2VLForConditionalGeneration.from_pretrained(model_path)
processor = AutoProcessor.from_pretrained(model_path)

# æµ‹è¯•
image = Image.open("/home/vgc7798/zheyu_b1222/example.jpeg")
question = "Based on the image, which view represents the resulting state?\n\nChoices:\nA. [Option A]\nB. [Option B]\nC. [Option C]\nD. [Option D]"

inputs = processor(text=question, images=image, return_tensors="pt")
outputs = model.generate(**inputs, max_new_tokens=100)
answer = processor.decode(outputs[0], skip_special_tokens=True)

print(f"Model answer: {answer}")
```

## ğŸ“ˆ æ€§èƒ½è°ƒä¼˜å»ºè®®

### 1. é’ˆå¯¹ä½ çš„æ•°æ®é›†å¤§å°

ä½ çš„æ•°æ®é›†å¦‚æœå¾ˆå¤§ (>10000 æ ·æœ¬):
```bash
trainer.total_epochs=10  # å‡å°‘è½®æ•°
data.train_batch_size=512  # å¢å¤§æ‰¹æ¬¡
```

æ•°æ®é›†è¾ƒå° (<1000 æ ·æœ¬):
```bash
trainer.total_epochs=30  # å¢åŠ è½®æ•°
data.train_batch_size=128  # å‡å°æ‰¹æ¬¡ï¼Œé¿å…è¿‡æ‹Ÿåˆ
```

### 2. ä½¿ç”¨ SGLang (æ¨è)

SGLang é€šå¸¸æ¯” vLLM å¿« 20-30%:
```bash
bash examples/grpo_trainer/run_qwen2_5_vl-3b_fake_dataset.sh sglang
```

### 3. å¤šèŠ‚ç‚¹è®­ç»ƒ

å¦‚æœæœ‰å¤šä¸ªèŠ‚ç‚¹:
```bash
trainer.nnodes=2  # ä½¿ç”¨ 2 ä¸ªèŠ‚ç‚¹
trainer.n_gpus_per_node=8
```

## ğŸ“š ä¸‹ä¸€æ­¥

è®­ç»ƒå®Œæˆåï¼Œä½ å¯ä»¥:

1. **è¯„ä¼°æ¨¡å‹**: åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°å‡†ç¡®ç‡
2. **å¾®è°ƒ Reward Function**: è°ƒæ•´ `mcq_vlm.py` ä¸­çš„å¥–åŠ±é€»è¾‘
3. **å°è¯•å…¶ä»–ç®—æ³•**: å°† `grpo` æ”¹ä¸º `ppo`
4. **ç»§ç»­è®­ç»ƒ**: ä» checkpoint ç»§ç»­è®­ç»ƒ

## ğŸ†˜ è·å–å¸®åŠ©

- **verl æ–‡æ¡£**: https://verl.readthedocs.io/
- **GitHub Issues**: https://github.com/volcengine/verl/issues
- **ç¤ºä¾‹ä»£ç **: `/gpfs/projects/p32509/userdata/zheyu/verl_Uky/examples/`

---

**ç¥è®­ç»ƒé¡ºåˆ©! ğŸ‰**

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥:
1. æ•°æ®é¢„å¤„ç†æ˜¯å¦æˆåŠŸ
2. å›¾åƒè·¯å¾„æ˜¯å¦æ­£ç¡®
3. GPU æ˜¾å­˜æ˜¯å¦å……è¶³
4. æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®
